{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boodscode237/scientific_seminary/blob/main/text_classification_using_lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9wbDH___gyb"
      },
      "source": [
        "## IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:16:15.796620Z",
          "iopub.status.busy": "2024-06-05T14:16:15.795895Z",
          "iopub.status.idle": "2024-06-05T14:16:21.573184Z",
          "shell.execute_reply": "2024-06-05T14:16:21.571989Z",
          "shell.execute_reply.started": "2024-06-05T14:16:15.796584Z"
        },
        "trusted": true,
        "id": "06whtogX_gyc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q peft transformers datasets evaluate seqeval pymorphy2  datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:16:21.576216Z",
          "iopub.status.busy": "2024-06-05T14:16:21.575805Z",
          "iopub.status.idle": "2024-06-05T14:16:39.960029Z",
          "shell.execute_reply": "2024-06-05T14:16:39.958881Z",
          "shell.execute_reply.started": "2024-06-05T14:16:21.576164Z"
        },
        "trusted": true,
        "id": "xV7z4u1c_gye"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:16:39.961717Z",
          "iopub.status.busy": "2024-06-05T14:16:39.961448Z",
          "iopub.status.idle": "2024-06-05T14:16:53.112798Z",
          "shell.execute_reply": "2024-06-05T14:16:53.111825Z",
          "shell.execute_reply.started": "2024-06-05T14:16:39.961692Z"
        },
        "trusted": true,
        "id": "PTRmtstd_gyf",
        "outputId": "fe3a199f-3698-4538-acb5-fde8125c3f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans in /opt/conda/lib/python3.10/site-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /opt/conda/lib/python3.10/site-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (2024.6.1)\n",
            "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /opt/conda/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /opt/conda/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /opt/conda/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade googletrans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:16:53.115239Z",
          "iopub.status.busy": "2024-06-05T14:16:53.114917Z",
          "iopub.status.idle": "2024-06-05T14:17:06.254443Z",
          "shell.execute_reply": "2024-06-05T14:17:06.253170Z",
          "shell.execute_reply.started": "2024-06-05T14:16:53.115209Z"
        },
        "trusted": true,
        "id": "LQ3nFKwo_gyh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install optuna scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:17:06.256461Z",
          "iopub.status.busy": "2024-06-05T14:17:06.256061Z",
          "iopub.status.idle": "2024-06-05T14:17:06.359136Z",
          "shell.execute_reply": "2024-06-05T14:17:06.358369Z",
          "shell.execute_reply.started": "2024-06-05T14:17:06.256424Z"
        },
        "trusted": true,
        "id": "WW8bzkVH_gyh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import torch\n",
        "from googletrans import Translator\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-05T14:15:47.843493Z",
          "iopub.status.idle": "2024-06-05T14:15:47.843950Z",
          "shell.execute_reply": "2024-06-05T14:15:47.843722Z",
          "shell.execute_reply.started": "2024-06-05T14:15:47.843704Z"
        },
        "trusted": true,
        "id": "2PX5PP4l_gyk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install ipython-autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T06:00:08.300019Z",
          "iopub.status.busy": "2024-06-03T06:00:08.299706Z",
          "iopub.status.idle": "2024-06-03T06:00:08.309546Z",
          "shell.execute_reply": "2024-06-03T06:00:08.308675Z",
          "shell.execute_reply.started": "2024-06-03T06:00:08.299992Z"
        },
        "trusted": true,
        "id": "5mBLlSbI_gyl",
        "outputId": "3a74e10a-0d18-42e3-b26d-73a71d17c610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 132 Âµs (started: 2024-06-03 06:00:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7IEz1kx_gyl"
      },
      "source": [
        "## DATASET UPLOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-03T06:00:08.311225Z",
          "iopub.status.busy": "2024-06-03T06:00:08.310885Z",
          "iopub.status.idle": "2024-06-03T06:00:08.322041Z",
          "shell.execute_reply": "2024-06-03T06:00:08.321197Z",
          "shell.execute_reply.started": "2024-06-03T06:00:08.311188Z"
        },
        "trusted": true,
        "id": "U8KJhhZG_gyl",
        "outputId": "7dd2c362-17e1-4ac1-f201-0b605a0774e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 7.09 ms (started: 2024-06-03 06:00:08 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:21:38.222729Z",
          "iopub.status.busy": "2024-06-05T14:21:38.222336Z",
          "iopub.status.idle": "2024-06-05T14:21:38.241011Z",
          "shell.execute_reply": "2024-06-05T14:21:38.239892Z",
          "shell.execute_reply.started": "2024-06-05T14:21:38.222697Z"
        },
        "trusted": true,
        "id": "pO2dby3s_gym"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/kaggle/input/financial-time-all-data/ft-all-data.csv', encoding='latin1', names=['sentiment', 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:21:42.508734Z",
          "iopub.status.busy": "2024-06-05T14:21:42.508254Z",
          "iopub.status.idle": "2024-06-05T14:21:42.521252Z",
          "shell.execute_reply": "2024-06-05T14:21:42.520122Z",
          "shell.execute_reply.started": "2024-06-05T14:21:42.508697Z"
        },
        "trusted": true,
        "id": "xeqTRB2g_gym",
        "outputId": "89d27e65-976c-4151-f67f-2be9c0576293"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>negative</td>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>negative</td>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>negative</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>negative</td>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4846 rows Ã 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentiment                                               text\n",
              "0      neutral  According to Gran , the company has no plans t...\n",
              "1      neutral  Technopolis plans to develop in stages an area...\n",
              "2     negative  The international electronic industry company ...\n",
              "3     positive  With the new production plant the company woul...\n",
              "4     positive  According to the company 's updated strategy f...\n",
              "...        ...                                                ...\n",
              "4841  negative  LONDON MarketWatch -- Share prices ended lower...\n",
              "4842   neutral  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
              "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...\n",
              "4844  negative  Net sales of the Paper segment decreased to EU...\n",
              "4845  negative  Sales in Finland decreased by 10.5 % in Januar...\n",
              "\n",
              "[4846 rows x 2 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:21:54.077519Z",
          "iopub.status.busy": "2024-06-05T14:21:54.076798Z",
          "iopub.status.idle": "2024-06-05T14:21:54.091986Z",
          "shell.execute_reply": "2024-06-05T14:21:54.090728Z",
          "shell.execute_reply.started": "2024-06-05T14:21:54.077485Z"
        },
        "trusted": true,
        "id": "mBSRJXUJ_gyn",
        "outputId": "8b7197b8-92ce-4d43-bb43-e7f651eac754"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                               text\n",
              "0   neutral  According to Gran , the company has no plans t...\n",
              "1   neutral  Technopolis plans to develop in stages an area...\n",
              "2  negative  The international electronic industry company ...\n",
              "3  positive  With the new production plant the company woul...\n",
              "4  positive  According to the company 's updated strategy f..."
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_mapping = {0: 'neutral', -1: 'negative', 1: 'positive'}\n",
        "\n",
        "data['sentiment'] = data['sentiment'].replace(sentiment_mapping)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OhUh3dt_gyn"
      },
      "source": [
        "### Data augmentation Using Translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:22:58.681158Z",
          "iopub.status.busy": "2024-06-05T14:22:58.680803Z",
          "iopub.status.idle": "2024-06-05T14:22:58.689725Z",
          "shell.execute_reply": "2024-06-05T14:22:58.688793Z",
          "shell.execute_reply.started": "2024-06-05T14:22:58.681132Z"
        },
        "trusted": true,
        "id": "IsygahYB_gyn"
      },
      "outputs": [],
      "source": [
        "texts = data['text'].tolist()\n",
        "labels = data['sentiment'].map({'positive': 0, 'neutral': 1, 'negative': 2}).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:23:45.635037Z",
          "iopub.status.busy": "2024-06-05T14:23:45.634408Z",
          "iopub.status.idle": "2024-06-05T14:23:45.642740Z",
          "shell.execute_reply": "2024-06-05T14:23:45.641631Z",
          "shell.execute_reply.started": "2024-06-05T14:23:45.635007Z"
        },
        "trusted": true,
        "id": "EwnDFgZA_gyn"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'text': texts, 'label': labels})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xghlm4lh_gyo"
      },
      "source": [
        "### create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:24:29.632655Z",
          "iopub.status.busy": "2024-06-05T14:24:29.631585Z",
          "iopub.status.idle": "2024-06-05T14:24:29.668359Z",
          "shell.execute_reply": "2024-06-05T14:24:29.667262Z",
          "shell.execute_reply.started": "2024-06-05T14:24:29.632615Z"
        },
        "trusted": true,
        "id": "1G88X6pC_gyo"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:24:33.572276Z",
          "iopub.status.busy": "2024-06-05T14:24:33.571883Z",
          "iopub.status.idle": "2024-06-05T14:24:33.578796Z",
          "shell.execute_reply": "2024-06-05T14:24:33.577852Z",
          "shell.execute_reply.started": "2024-06-05T14:24:33.572244Z"
        },
        "trusted": true,
        "id": "QI5s_2tC_gyo",
        "outputId": "7ce644cf-e8f6-4816-f614-25a2a5178e99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 4846\n",
              "})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yywbcgfh_gyo"
      },
      "source": [
        "## Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:25:31.550189Z",
          "iopub.status.busy": "2024-06-05T14:25:31.549822Z",
          "iopub.status.idle": "2024-06-05T14:25:31.577146Z",
          "shell.execute_reply": "2024-06-05T14:25:31.576373Z",
          "shell.execute_reply.started": "2024-06-05T14:25:31.550160Z"
        },
        "trusted": true,
        "id": "XOUmykPZ_gyp"
      },
      "outputs": [],
      "source": [
        "train_val_dataset, test_dataset = dataset.train_test_split(test_size=0.2, seed=42).values()\n",
        "train_dataset, val_dataset = train_val_dataset.train_test_split(test_size=0.25, seed=42).values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEgaAN9m_gyp"
      },
      "source": [
        "### Tokenize the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwsf19gz_gyp"
      },
      "source": [
        "## Set Up Cross-Validation and Define Objective Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:28:36.130663Z",
          "iopub.status.busy": "2024-06-05T14:28:36.129642Z",
          "iopub.status.idle": "2024-06-05T14:28:49.545192Z",
          "shell.execute_reply": "2024-06-05T14:28:49.544084Z",
          "shell.execute_reply.started": "2024-06-05T14:28:36.130631Z"
        },
        "trusted": true,
        "id": "pYWLGgPN_gyp"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:26:04.157779Z",
          "iopub.status.busy": "2024-06-05T14:26:04.157109Z",
          "iopub.status.idle": "2024-06-05T14:26:20.880934Z",
          "shell.execute_reply": "2024-06-05T14:26:20.879940Z",
          "shell.execute_reply.started": "2024-06-05T14:26:04.157750Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "4ca51fc4d49a4b77b949291d94e43853",
            "b570d73b0165489d8b18884fa324f77a",
            "fcd2b71dba96469d9e9c15e476b1feea",
            "c83ed950bd434c4494b10078bc855c8c",
            "020b8981f8994992bd0ef1182b16660e",
            "f48fe5ab15f748b3a84545813edf3df5",
            "40e7fe7bd0c349529c3259cc87c3935b"
          ]
        },
        "id": "hhViHuHT_gyp",
        "outputId": "8d73fd70-cdc1-4f31-f1bd-4bcbefaf6b71"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ca51fc4d49a4b77b949291d94e43853",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b570d73b0165489d8b18884fa324f77a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcd2b71dba96469d9e9c15e476b1feea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c83ed950bd434c4494b10078bc855c8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "020b8981f8994992bd0ef1182b16660e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2907 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f48fe5ab15f748b3a84545813edf3df5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/969 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40e7fe7bd0c349529c3259cc87c3935b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "model_name = \"distilbert-base-multilingual-cased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:26:26.225579Z",
          "iopub.status.busy": "2024-06-05T14:26:26.225186Z",
          "iopub.status.idle": "2024-06-05T14:26:59.079144Z",
          "shell.execute_reply": "2024-06-05T14:26:59.078215Z",
          "shell.execute_reply.started": "2024-06-05T14:26:26.225549Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "d7e691b0e7df4b8284fa6ab076e79250"
          ]
        },
        "id": "bb1OJg5x_gyq",
        "outputId": "139947bc-a73e-49b4-c267-7f3be84b3ffc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7e691b0e7df4b8284fa6ab076e79250",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:27:10.693607Z",
          "iopub.status.busy": "2024-06-05T14:27:10.692517Z",
          "iopub.status.idle": "2024-06-05T14:27:23.606641Z",
          "shell.execute_reply": "2024-06-05T14:27:23.605225Z",
          "shell.execute_reply.started": "2024-06-05T14:27:10.693568Z"
        },
        "trusted": true,
        "id": "eJR4Y4Fh_gyq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:28:58.382552Z",
          "iopub.status.busy": "2024-06-05T14:28:58.382135Z",
          "iopub.status.idle": "2024-06-05T14:28:59.764708Z",
          "shell.execute_reply": "2024-06-05T14:28:59.763752Z",
          "shell.execute_reply.started": "2024-06-05T14:28:58.382520Z"
        },
        "trusted": true,
        "id": "Rc53ih-Z_gyq"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T14:29:28.472855Z",
          "iopub.status.busy": "2024-06-05T14:29:28.471862Z",
          "iopub.status.idle": "2024-06-05T15:12:54.687718Z",
          "shell.execute_reply": "2024-06-05T15:12:54.686714Z",
          "shell.execute_reply.started": "2024-06-05T14:29:28.472814Z"
        },
        "trusted": true,
        "id": "ldr-Z30s_gyr",
        "outputId": "b6e73977-f85b-43cd-ffab-f848ae23a67a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:29:28,480] A new study created in memory with name: no-name-3a591cdd-00a3-40a7-a334-47ef354e9ddd\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20240605_142945-r8rendev</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/boodscode237/huggingface/runs/r8rendev' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/boodscode237/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/boodscode237/huggingface' target=\"_blank\">https://wandb.ai/boodscode237/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/boodscode237/huggingface/runs/r8rendev' target=\"_blank\">https://wandb.ai/boodscode237/huggingface/runs/r8rendev</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='728' max='728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [728/728 04:51, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.864967</td>\n",
              "      <td>0.610939</td>\n",
              "      <td>0.465543</td>\n",
              "      <td>0.762621</td>\n",
              "      <td>0.610939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.778836</td>\n",
              "      <td>0.659443</td>\n",
              "      <td>0.588547</td>\n",
              "      <td>0.672987</td>\n",
              "      <td>0.659443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.857000</td>\n",
              "      <td>0.749089</td>\n",
              "      <td>0.673891</td>\n",
              "      <td>0.618592</td>\n",
              "      <td>0.691373</td>\n",
              "      <td>0.673891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.857000</td>\n",
              "      <td>0.741202</td>\n",
              "      <td>0.672859</td>\n",
              "      <td>0.620187</td>\n",
              "      <td>0.691771</td>\n",
              "      <td>0.672859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [61/61 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:35:05,893] Trial 0 finished with value: 0.672858617131063 and parameters: {'learning_rate': 1.927633804869361e-05, 'batch_size': 16, 'num_train_epochs': 4, 'lora_alpha': 25, 'r': 7}. Best is trial 0 with value: 0.672858617131063.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1456' max='1456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1456/1456 05:06, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.882166</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.931800</td>\n",
              "      <td>0.829806</td>\n",
              "      <td>0.626419</td>\n",
              "      <td>0.513111</td>\n",
              "      <td>0.626600</td>\n",
              "      <td>0.626419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.843600</td>\n",
              "      <td>0.792806</td>\n",
              "      <td>0.658411</td>\n",
              "      <td>0.580505</td>\n",
              "      <td>0.671362</td>\n",
              "      <td>0.658411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.843600</td>\n",
              "      <td>0.783604</td>\n",
              "      <td>0.664603</td>\n",
              "      <td>0.592165</td>\n",
              "      <td>0.678138</td>\n",
              "      <td>0.664603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:40:23,901] Trial 1 finished with value: 0.6646026831785345 and parameters: {'learning_rate': 1.2530862119024624e-05, 'batch_size': 8, 'num_train_epochs': 4, 'lora_alpha': 9, 'r': 7}. Best is trial 0 with value: 0.672858617131063.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1092' max='1092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1092/1092 03:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.752945</td>\n",
              "      <td>0.651187</td>\n",
              "      <td>0.598761</td>\n",
              "      <td>0.679761</td>\n",
              "      <td>0.651187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.830100</td>\n",
              "      <td>0.684918</td>\n",
              "      <td>0.693498</td>\n",
              "      <td>0.651657</td>\n",
              "      <td>0.666376</td>\n",
              "      <td>0.693498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.687200</td>\n",
              "      <td>0.667801</td>\n",
              "      <td>0.687307</td>\n",
              "      <td>0.652097</td>\n",
              "      <td>0.663246</td>\n",
              "      <td>0.687307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:44:25,530] Trial 2 finished with value: 0.6873065015479877 and parameters: {'learning_rate': 3.085847247531291e-05, 'batch_size': 8, 'num_train_epochs': 3, 'lora_alpha': 24, 'r': 10}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='728' max='728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [728/728 02:32, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.737677</td>\n",
              "      <td>0.656347</td>\n",
              "      <td>0.604103</td>\n",
              "      <td>0.685012</td>\n",
              "      <td>0.656347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.812900</td>\n",
              "      <td>0.697179</td>\n",
              "      <td>0.680083</td>\n",
              "      <td>0.635419</td>\n",
              "      <td>0.654602</td>\n",
              "      <td>0.680083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:47:08,797] Trial 3 finished with value: 0.6800825593395253 and parameters: {'learning_rate': 4.1436660106206595e-05, 'batch_size': 8, 'num_train_epochs': 2, 'lora_alpha': 17, 'r': 16}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1092' max='1092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1092/1092 03:51, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.787414</td>\n",
              "      <td>0.662539</td>\n",
              "      <td>0.597485</td>\n",
              "      <td>0.680306</td>\n",
              "      <td>0.662539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.858500</td>\n",
              "      <td>0.729862</td>\n",
              "      <td>0.681115</td>\n",
              "      <td>0.628952</td>\n",
              "      <td>0.656147</td>\n",
              "      <td>0.681115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.735100</td>\n",
              "      <td>0.717461</td>\n",
              "      <td>0.678019</td>\n",
              "      <td>0.630247</td>\n",
              "      <td>0.660850</td>\n",
              "      <td>0.678019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:51:11,086] Trial 4 finished with value: 0.6780185758513931 and parameters: {'learning_rate': 2.6858546565186742e-05, 'batch_size': 8, 'num_train_epochs': 3, 'lora_alpha': 15, 'r': 7}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1092' max='1092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1092/1092 03:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.787677</td>\n",
              "      <td>0.661507</td>\n",
              "      <td>0.593606</td>\n",
              "      <td>0.677609</td>\n",
              "      <td>0.661507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.863700</td>\n",
              "      <td>0.722132</td>\n",
              "      <td>0.678019</td>\n",
              "      <td>0.624263</td>\n",
              "      <td>0.677077</td>\n",
              "      <td>0.678019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.729900</td>\n",
              "      <td>0.708126</td>\n",
              "      <td>0.676987</td>\n",
              "      <td>0.627541</td>\n",
              "      <td>0.665113</td>\n",
              "      <td>0.676987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 14:55:12,634] Trial 5 finished with value: 0.6769865841073271 and parameters: {'learning_rate': 2.032266677854727e-05, 'batch_size': 8, 'num_train_epochs': 3, 'lora_alpha': 28, 'r': 9}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1456' max='1456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1456/1456 05:05, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.871369</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.921600</td>\n",
              "      <td>0.789122</td>\n",
              "      <td>0.656347</td>\n",
              "      <td>0.577829</td>\n",
              "      <td>0.667556</td>\n",
              "      <td>0.656347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>0.757309</td>\n",
              "      <td>0.669763</td>\n",
              "      <td>0.605828</td>\n",
              "      <td>0.688356</td>\n",
              "      <td>0.669763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.803700</td>\n",
              "      <td>0.749780</td>\n",
              "      <td>0.670795</td>\n",
              "      <td>0.608683</td>\n",
              "      <td>0.690793</td>\n",
              "      <td>0.670795</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 15:00:29,357] Trial 6 finished with value: 0.6707946336429309 and parameters: {'learning_rate': 1.0901155557428154e-05, 'batch_size': 8, 'num_train_epochs': 4, 'lora_alpha': 28, 'r': 4}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='182' max='182' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [182/182 02:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.909399</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.899520</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31/31 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 15:03:02,227] Trial 7 finished with value: 0.608875128998968 and parameters: {'learning_rate': 1.7191186281911664e-05, 'batch_size': 32, 'num_train_epochs': 2, 'lora_alpha': 11, 'r': 7}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='364' max='364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [364/364 04:43, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.897848</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.869103</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.840069</td>\n",
              "      <td>0.621259</td>\n",
              "      <td>0.498619</td>\n",
              "      <td>0.612000</td>\n",
              "      <td>0.621259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.828775</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.524911</td>\n",
              "      <td>0.510837</td>\n",
              "      <td>0.631579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31/31 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 15:07:57,568] Trial 8 finished with value: 0.631578947368421 and parameters: {'learning_rate': 1.99972848755622e-05, 'batch_size': 32, 'num_train_epochs': 4, 'lora_alpha': 18, 'r': 12}. Best is trial 2 with value: 0.6873065015479877.\n",
            "/tmp/ipykernel_34/1780483025.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='364' max='364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [364/364 04:45, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.899968</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.867948</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>0.460855</td>\n",
              "      <td>0.761854</td>\n",
              "      <td>0.608875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.834422</td>\n",
              "      <td>0.628483</td>\n",
              "      <td>0.515620</td>\n",
              "      <td>0.632058</td>\n",
              "      <td>0.628483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.822087</td>\n",
              "      <td>0.643963</td>\n",
              "      <td>0.546710</td>\n",
              "      <td>0.652117</td>\n",
              "      <td>0.643963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31/31 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-05 15:12:54,682] Trial 9 finished with value: 0.6439628482972136 and parameters: {'learning_rate': 1.779585889410396e-05, 'batch_size': 32, 'num_train_epochs': 4, 'lora_alpha': 29, 'r': 13}. Best is trial 2 with value: 0.6873065015479877.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters:  {'learning_rate': 3.085847247531291e-05, 'batch_size': 8, 'num_train_epochs': 3, 'lora_alpha': 24, 'r': 10}\n"
          ]
        }
      ],
      "source": [
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted', zero_division=1)\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 4)\n",
        "    lora_alpha = trial.suggest_int('lora_alpha', 8, 32)\n",
        "    r = trial.suggest_int('r', 4, 16)\n",
        "\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "    config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"attention.q_lin\", \"attention.k_lin\", \"attention.v_lin\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"SEQ_CLS\"\n",
        "    )\n",
        "    model = get_peft_model(model, config)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    eval_result = trainer.evaluate(eval_dataset=val_dataset)\n",
        "\n",
        "    return eval_result['eval_accuracy']\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "print(\"Best hyperparameters: \", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhZdBtJ_gyr"
      },
      "source": [
        "## **Train the Final Model with Best Hyperparameters and Quantize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-05T15:24:09.213868Z",
          "iopub.status.busy": "2024-06-05T15:24:09.213469Z",
          "iopub.status.idle": "2024-06-05T15:34:34.619638Z",
          "shell.execute_reply": "2024-06-05T15:34:34.618556Z",
          "shell.execute_reply.started": "2024-06-05T15:24:09.213830Z"
        },
        "trusted": true,
        "id": "yP48fOUT_gys",
        "outputId": "8bb76063-7a69-4342-8f24-977af6ad4588"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2912' max='2912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2912/2912 10:13, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.656603</td>\n",
              "      <td>0.723426</td>\n",
              "      <td>0.706423</td>\n",
              "      <td>0.710517</td>\n",
              "      <td>0.723426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.753800</td>\n",
              "      <td>0.571934</td>\n",
              "      <td>0.747162</td>\n",
              "      <td>0.727963</td>\n",
              "      <td>0.737734</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.538100</td>\n",
              "      <td>0.487077</td>\n",
              "      <td>0.802890</td>\n",
              "      <td>0.799450</td>\n",
              "      <td>0.799749</td>\n",
              "      <td>0.802890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.538100</td>\n",
              "      <td>0.464848</td>\n",
              "      <td>0.819401</td>\n",
              "      <td>0.817629</td>\n",
              "      <td>0.816981</td>\n",
              "      <td>0.819401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.436800</td>\n",
              "      <td>0.452068</td>\n",
              "      <td>0.825593</td>\n",
              "      <td>0.823420</td>\n",
              "      <td>0.822997</td>\n",
              "      <td>0.825593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.450334</td>\n",
              "      <td>0.827657</td>\n",
              "      <td>0.826734</td>\n",
              "      <td>0.826315</td>\n",
              "      <td>0.827657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.391100</td>\n",
              "      <td>0.451007</td>\n",
              "      <td>0.827657</td>\n",
              "      <td>0.826337</td>\n",
              "      <td>0.825843</td>\n",
              "      <td>0.827657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.391100</td>\n",
              "      <td>0.451998</td>\n",
              "      <td>0.826625</td>\n",
              "      <td>0.825517</td>\n",
              "      <td>0.824961</td>\n",
              "      <td>0.826625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122' max='122' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122/122 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "best_params = {'learning_rate': 4.993596574084884e-05, 'batch_size': 8, 'num_train_epochs': 8, 'lora_alpha': 32, 'r': 8}\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "config = LoraConfig(\n",
        "    r=best_params['r'],\n",
        "    lora_alpha=best_params['lora_alpha'],\n",
        "    target_modules=[\"attention.q_lin\", \"attention.k_lin\", \"attention.v_lin\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    per_device_train_batch_size=best_params['batch_size'],\n",
        "    per_device_eval_batch_size=best_params['batch_size'],\n",
        "    num_train_epochs=best_params['num_train_epochs'],\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate(eval_dataset=test_dataset)\n",
        "\n",
        "trainer.save_model('./optimized_lora_distilbert_model_yesterday_params')"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5134456,
          "sourceId": 8584803,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5134469,
          "sourceId": 8584821,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5134939,
          "sourceId": 8585443,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5139346,
          "sourceId": 8591843,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5141113,
          "sourceId": 8594148,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5142435,
          "sourceId": 8595963,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30716,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}